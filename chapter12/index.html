<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title> | </title><meta name="Description" content="About uBlogger Theme"><meta property="og:title" content="" />
<meta property="og:description" content="1. General Regression Analysis 
统计：计量经济学——推断统计；经济统计——描述统计。
核心逻辑$\hat{\beta} \overset{p}{\rightarrow} \beta^ * \overset{模型正确设定}{=} \beta ^o$
当且仅当模型正确设定时，$\beta^*$可以被解释为边际效应
Hausman检验可以用来检验设否正确设定
当假定$u$服从正太分布时，$E(xu)=0$与$E(u|X)=0$等价
$$ \operatorname{MSE}{T}(\theta)=\operatorname{Var}{\theta}(T)&#43;\left[B_{T}(\theta)\right]^{2} $$
1.1 回归本质在估计$E(Y|X) $ 在经典回归模型中，我们希望用解释变量(regressand)$X$的函数$g(X)$来预测被解释变量(regressor)$Y$。此时需要一个标准来测度$g(X)$与$Y$的接近程度，均方误(mean squared error, MSE)准则最常被使用，MSE是预测误差（预测值$g(X)$与目标$Y$之差）的平方的期望，表达式如下 $$ \operatorname{MSE}(g)=E[Y-g(X)]^{2} = \int\int[y-g(x)]^2f_{XY}(x,y)\mathrm{d} x\mathrm{d} y $$
其中，$f_{XY}(x,y)$是变量$X$和$Y$的联合概率分布。
显然，MSE越小，$g(X)$对$Y$的预测能力越强。因此现在的问题转换为，求解使MSE最小的函数$g(·)$，注意到MSE是函数$g(·)$的函数。
事实上，条件均值$E(Y|X)$就是使MSE最小的函数$g_0(X)$，可以用求微分和方差分解两种方法证明（证明见文末附录）。
需要注意的是，条件均值$E(Y|X)$是$X$而非$Y$的函数。
MSE是衡量$g(X)$对$Y$的预测能力的准则之一，但非唯一准则。例如，平均绝对误差(mean absolute error, MAE)，
$$ \operatorname{MAE}(g)=E|Y-g(X)| $$
此时，使MAE最小的函数$g(X)$是条件中位数，分位数回归采用的正是该准则。
相比MAE，MSE具有连续可导的优良性质。
令回归等式$Y=E(Y | X)&#43;\varepsilon$，其中$\varepsilon$被称为回归扰动项，则有 $$ \begin{aligned} E(\varepsilon | X) &amp;=E{[Y-E(Y | X)] | X} \ &amp;=E(Y | X)-E\left[g_{o}(X) | X\right] \ &amp;=E(Y | X)-g_{o}(X) \ &amp;=0 \end{aligned} $$" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://henrywu97.github.io/chapter12/" />
<meta property="og:image" content="https://henrywu97.github.io/logo.png"/>
<meta property="article:modified_time" content="2021-02-06T20:37:07+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://henrywu97.github.io/logo.png"/>

<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="1. General Regression Analysis 
统计：计量经济学——推断统计；经济统计——描述统计。
核心逻辑$\hat{\beta} \overset{p}{\rightarrow} \beta^ * \overset{模型正确设定}{=} \beta ^o$
当且仅当模型正确设定时，$\beta^*$可以被解释为边际效应
Hausman检验可以用来检验设否正确设定
当假定$u$服从正太分布时，$E(xu)=0$与$E(u|X)=0$等价
$$ \operatorname{MSE}{T}(\theta)=\operatorname{Var}{\theta}(T)&#43;\left[B_{T}(\theta)\right]^{2} $$
1.1 回归本质在估计$E(Y|X) $ 在经典回归模型中，我们希望用解释变量(regressand)$X$的函数$g(X)$来预测被解释变量(regressor)$Y$。此时需要一个标准来测度$g(X)$与$Y$的接近程度，均方误(mean squared error, MSE)准则最常被使用，MSE是预测误差（预测值$g(X)$与目标$Y$之差）的平方的期望，表达式如下 $$ \operatorname{MSE}(g)=E[Y-g(X)]^{2} = \int\int[y-g(x)]^2f_{XY}(x,y)\mathrm{d} x\mathrm{d} y $$
其中，$f_{XY}(x,y)$是变量$X$和$Y$的联合概率分布。
显然，MSE越小，$g(X)$对$Y$的预测能力越强。因此现在的问题转换为，求解使MSE最小的函数$g(·)$，注意到MSE是函数$g(·)$的函数。
事实上，条件均值$E(Y|X)$就是使MSE最小的函数$g_0(X)$，可以用求微分和方差分解两种方法证明（证明见文末附录）。
需要注意的是，条件均值$E(Y|X)$是$X$而非$Y$的函数。
MSE是衡量$g(X)$对$Y$的预测能力的准则之一，但非唯一准则。例如，平均绝对误差(mean absolute error, MAE)，
$$ \operatorname{MAE}(g)=E|Y-g(X)| $$
此时，使MAE最小的函数$g(X)$是条件中位数，分位数回归采用的正是该准则。
相比MAE，MSE具有连续可导的优良性质。
令回归等式$Y=E(Y | X)&#43;\varepsilon$，其中$\varepsilon$被称为回归扰动项，则有 $$ \begin{aligned} E(\varepsilon | X) &amp;=E{[Y-E(Y | X)] | X} \ &amp;=E(Y | X)-E\left[g_{o}(X) | X\right] \ &amp;=E(Y | X)-g_{o}(X) \ &amp;=0 \end{aligned} $$"/>
<meta name="application-name" content="uBlogger">
<meta name="apple-mobile-web-app-title" content="uBlogger"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://henrywu97.github.io/chapter12/" /><link rel="prev" href="https://henrywu97.github.io/5.-modern-portfolio-theory/" /><link rel="next" href="https://henrywu97.github.io/6.-instrumental-variables-regression/" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/henrywu97.github.io\/chapter12\/"
        },"image": [{
                            "@type": "ImageObject",
                            "url": "https:\/\/henrywu97.github.io\/images\/Apple-Devices-Preview.png",
                            "width":  3200 ,
                            "height":  2048 
                        }],"genre": "posts","wordCount":  1373 ,
        "url": "https:\/\/henrywu97.github.io\/chapter12\/","dateModified": "2021-02-06T20:37:07+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": {
                    "@type": "ImageObject",
                    "url": "https:\/\/henrywu97.github.io\/images\/avatar.png",
                    "width":  528 ,
                    "height":  560 
                }},"author": {
                "@type": "Person",
                "name": "天天.zh-cn"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script>(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('light' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'light' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Henry Wu" class="header-logo"><span class="header-title-pre"><i class='fas fa-pencil-alt fa-fw'></i></span>Henry Wu</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="/about/"> About </a><a class="menu-item" href="https://github.com/henrywu97" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i>  </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item language" title="Select Language">English<i class="fas fa-chevron-right fa-fw"></i>
                        <select class="language-select" id="language-select-desktop" onchange="location = this.value;"><option value="/chapter12/" selected>English</option></select>
                    </a><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Henry Wu" class="header-logo"><span class="header-title-pre"><i class='fas fa-pencil-alt fa-fw'></i></span>Henry Wu</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="/about/" title="">About</a><a class="menu-item" href="https://github.com/henrywu97" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a><a href="javascript:void(0);" class="menu-item" title="Select Language">English<i class="fas fa-chevron-right fa-fw"></i>
                    <select class="language-select" onchange="location = this.value;"><option value="/chapter12/" selected>English</option></select>
                </a></div>
    </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div><main class="main"><div class="container content-article page-toc theme-classic"><div class="toc" id="toc-auto">
            <div class="toc-title">Contents</div>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><div class="header-post">
        <div class="post-title">

            <div class="post-all-meta">
            <div class="breadcrumbs">
    <a href="/">Home </a>/ <a href="/">  </a>
</div>
            <h1 class="single-title animated flipInX"></h1><div class="post-meta">
                <div class="post-meta-line">&nbsp;&nbsp;&nbsp;&nbsp;<i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time class="timeago" datetime="0001-01-01">0001-01-01</time>&nbsp;&nbsp;&nbsp;&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;1373 words
                    &nbsp;&nbsp;&nbsp;&nbsp;<i class="far fa-clock fa-fw"></i>&nbsp;7 minutes</div>
            </div>
        </div>


    </div>

    </div>

        <article class="single toc-start">

        <div class="content-block content-block-first content-block-position">

        <div class="post"><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#11-回归本质在估计eyx-">1.1 回归本质在估计$E(Y|X) $</a></li>
        <li><a href="#附录">附录</a></li>
        <li><a href="#12-最优线性最小二乘估计beta-">1.2 最优线性最小二乘估计$\beta^* $</a></li>
        <li><a href="#13-模型正确设定">1.3 模型正确设定</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#21-假定">2.1 假定</a>
      <ul>
        <li>
          <ul>
            <li><a href="#假设31-线性">假设3.1 线性</a></li>
            <li><a href="#假设32-严格外生性">假设3.2 严格外生性</a></li>
            <li><a href="#假设33-非奇异">假设3.3 非奇异</a></li>
            <li><a href="#假设34-球形误差方差">假设3.4 球形误差方差</a></li>
            <li><a href="#假设35-条件正态分布">假设3.5 条件正态分布</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#22-普通最小二乘估计ols">2.2 普通最小二乘估计OLS</a>
      <ul>
        <li><a href="#221-ols估计量的存在性">2.2.1 OLS估计量的存在性</a></li>
        <li><a href="#222-hatbeta与-beta-">2.2.2 $\hat{\beta}$与$ \beta^* $</a></li>
        <li><a href="#223-残差及其性质">2.2.3 残差及其性质</a></li>
      </ul>
    </li>
    <li><a href="#23-拟合优度与模型选择准则">2.3 拟合优度与模型选择准则</a>
      <ul>
        <li><a href="#231-拟合优度-mathcalr2-">2.3.1 拟合优度$ \mathcal{R}^2 $</a></li>
        <li><a href="#232-aicbic">2.3.2 AIC&amp;BIC</a></li>
      </ul>
    </li>
    <li><a href="#24-ols估计量的统计性质">2.4 OLS估计量的统计性质</a></li>
    <li><a href="#25-ols估计量的抽样分布">2.5 OLS估计量的抽样分布</a></li>
    <li><a href="#26-残差方差估计量的分布">2.6 残差方差估计量的分布</a></li>
    <li><a href="#27-假设检验">2.7 假设检验</a>
      <ul>
        <li><a href="#271-j1">2.7.1 J=1</a></li>
        <li><a href="#272-j1">2.7.2 J&gt;1</a></li>
      </ul>
    </li>
    <li><a href="#28-重要应用">2.8 重要应用</a>
      <ul>
        <li><a href="#281-检验所有解释变量的联合显著性">2.8.1 检验所有解释变量的联合显著性</a></li>
        <li><a href="#283-检验遗漏变量">2.8.3 检验遗漏变量</a></li>
      </ul>
    </li>
    <li><a href="#29-广义最小二乘估计gls">2.9 广义最小二乘估计GLS</a></li>
  </ul>
</nav></div>
            </div><span class="post-update">
                    <b>Updated on 2021-02-06</b>
                </span><h1 id="1-general-regression-analysis">1. General Regression Analysis</h1>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223329.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223329.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223329.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223329.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223329.png"
        title="20200611223329.png" /></div></p>
<p>统计：计量经济学——推断统计；经济统计——描述统计。</p>
<p>核心逻辑$\hat{\beta} \overset{p}{\rightarrow}  \beta^ * \overset{模型正确设定}{=} \beta ^o$</p>
<p>当且仅当模型正确设定时，$\beta^*$可以被解释为边际效应</p>
<p>Hausman检验可以用来检验设否正确设定</p>
<p>当假定$u$服从正太分布时，$E(xu)=0$与$E(u|X)=0$等价</p>
<p><img src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223348.png" alt="image-20200218095533580" style="zoom:67%;" />
$$
\operatorname{MSE}<em>{T}(\theta)=\operatorname{Var}</em>{\theta}(T)+\left[B_{T}(\theta)\right]^{2}
$$</p>
<p><img src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223530.png" alt="image-20200218113301756" style="zoom:67%;" /></p>
<h3 id="11-回归本质在估计eyx-">1.1 回归本质在估计$E(Y|X) $</h3>
<p>在经典回归模型中，我们希望用解释变量(regressand)$X$的函数$g(X)$来预测被解释变量(regressor)$Y$。此时需要一个标准来测度$g(X)$与$Y$的接近程度，<strong>均方误(mean squared error, MSE)准则</strong>最常被使用，MSE是预测误差（预测值$g(X)$与目标$Y$之差）的平方的期望，表达式如下
$$
\operatorname{MSE}(g)=E[Y-g(X)]^{2} = \int\int[y-g(x)]^2f_{XY}(x,y)\mathrm{d} x\mathrm{d} y
$$</p>
<p>其中，$f_{XY}(x,y)$是变量$X$和$Y$的联合概率分布。</p>
<p>显然，MSE越小，$g(X)$对$Y$的预测能力越强。因此现在的问题转换为，<strong>求解使MSE最小的函数$g(·)$</strong>，注意到MSE是函数$g(·)$的函数。</p>
<p>事实上，<strong>条件均值$E(Y|X)$就是使MSE最小的函数$g_0(X)$</strong>，可以用求微分和方差分解两种方法证明（证明见文末附录）。</p>
<p>需要注意的是，条件均值$E(Y|X)$是$X$而非$Y$的函数。</p>
<p>MSE是衡量$g(X)$对$Y$的预测能力的准则之一，但非唯一准则。例如，平均绝对误差(mean absolute error, MAE)，</p>
<p>$$
\operatorname{MAE}(g)=E|Y-g(X)|
$$</p>
<p>此时，<strong>使MAE最小的函数$g(X)$是条件中位数</strong>，分位数回归采用的正是该准则。</p>
<p>相比MAE，MSE具有连续可导的优良性质。</p>
<p>令<strong>回归等式</strong>$Y=E(Y | X)+\varepsilon$，其中$\varepsilon$被称为回归扰动项，则有
$$
\begin{aligned} E(\varepsilon | X) &amp;=E{[Y-E(Y | X)] | X} 
\ &amp;=E(Y | X)-E\left[g_{o}(X) | X\right] 
\ &amp;=E(Y | X)-g_{o}(X) 
\ &amp;=0 \end{aligned}
$$</p>
<p><strong>$E(\varepsilon|X) = 0$意味着$\varepsilon$不包含可用于预测$Y$的期望值的任何有关$X$的信息。换句话说，可用于预测$Y$的所有$X$的信息被包含在$E(Y|X)$中</strong>。</p>
<p>进一步，
$$
E(\varepsilon)= E[E(\varepsilon | X)]=0
$$
$\varepsilon$与$X$正交
$$
\begin{aligned}
E(X \varepsilon) &amp;=E[X E(\varepsilon | X)] \<br>
&amp;=E(X \cdot 0) \<br>
&amp;=0
\end{aligned}
$$
事实上 ，$E[\varepsilon h(X)]=0$ (对于任一的可测函数$h(·)$)与$E(\varepsilon |X)=0$等价。这说明即使用非线性的模型，也无法改进预测效果。</p>
<h3 id="附录">附录</h3>
<p><strong>引理：重复期望法则</strong>(Law of Iterated Expectations, LIE)，对给定可测函数$G(X,Y)$，假设期望$E[G(X,Y)]$存在，则</p>
<p>$$
E[G(X, Y)]=E{E[G(X, Y) | X]}
$$</p>
<p>证明：仅考虑$\left(Y,X^{\prime}\right)^{\prime}$是连续随机向量的情形，有</p>
<p>$$
\begin{aligned} E[G(X, Y)] &amp;=\iint_{-\infty}^{\infty} G(x, y) f_{X Y}(x, y) \mathrm{d} x \mathrm{d} y \ &amp;=\iint_{-\infty}^{\infty} G(x, y) f_{Y | X}(y | x) f_{X}(x) \mathrm{d} x \mathrm{d} y \ &amp;=\int\left[\int_{-\infty}^{\infty} G(x, y) f_{Y | X}(y | x) \mathrm{d} y\right] f_{X}(x) \mathrm{d} x \ &amp;=\int E[G(X, Y) | X=x] f_{X}(x) \mathrm{d} x \ &amp;=E{E[G(X, Y) | X]} \end{aligned}
$$</p>
<p>If $J$ contains more information than $I$, similarly, we have
$$
E(Y|I) = E[E(Y|J)|I]
$$</p>
<p><strong>定理</strong>：条件均值$E(Y|X)$是下列问题的最优解
$$
\begin{aligned} E(Y | X) &amp;=\arg \min _{g \in \mathbb{F}} M S E(g) \ &amp;=\arg \min _{g \in \mathbb{F}} E[Y-g(X)]^{2} \end{aligned}
$$</p>
<p>其中$\mathbb{F}$是所有可测和平方可积函数的集合，即</p>
<p>$$
\mathbb{F}=\left{g: \mathbb{R}^{k+1} \rightarrow \mathbb{R} | \int g^{2}(x) f_{X}(x) \mathrm{d} x&lt;\infty\right}
$$</p>
<p><strong>法一</strong>：方差分解</p>
<p>令$g_{0}(X) = E(Y | X)$，则</p>
<p>$$
\begin{aligned} \operatorname{MSE}(g) &amp;=E\left[Y-g_{0}(X)+g_{0}(X)-g(X)\right]^{2} \ &amp;=E\left[Y-g_{0}(X)\right]^{2}+E\left[g_{0}(X)-g(X)\right]^{2}+2 E\left{\left[Y-g_{0}(X)\right]\left[g_{0}(X)-g(X)\right]\right}  \end{aligned}
$$</p>
<p>根据重复期望法则</p>
<p>$$
\begin{aligned} E\left{\left[Y-g_{0}(X)\right]\left[g_{0}(X)-g(X)\right]\right}
&amp;=E\left{E\left(\left[Y-g_{0}(X)\right]\left[g_{0}(X)-g(X)\right]|X\right)\right}
\ &amp;=E\left{\left[g_{0}(X)-g(X)\right]E\left(\left[Y-g_{0}(X)\right]|X\right)\right}
\ &amp;=E\left{\left[g_{0}(X)-g(X)\right][E(Y|X)-g_{0}(X)]\right}
\ &amp;=E\left{\left[g_{0}(X)-g(X)\right]·0\right}
\ &amp;=0
\end{aligned}
$$</p>
<p>$$
\implies MSE(g) =E\left[Y-g_{0}(X)\right]^{2}+E\left[g_{0}(X)-g(X)\right]^{2}
$$</p>
<p>$$
\implies \arg \min _{g \in \mathbb{F}} M S E(g) = g_0(X) = E(Y|X)
$$</p>
<p><strong>法二</strong>：求微分法</p>
<p>$$
\operatorname{MSE}(g)=E[Y-g(X)]^{2} = \int\int[y-g(x)]^2f_{XY}(x,y)\mathrm{d} x\mathrm{d} y
$$</p>
<p>根据一阶条件，MSE对$g(X)$的导数为0
$$
\frac{\delta MSE(g)}{\delta g(x)}=-2\int[y-g(x)] f_{XY}(x,y) \mathrm{d} y=0
$$</p>
<p>$$
\implies \int g(x)f_{XY}(x,y) \mathrm{d}y = \int yf_{XY}(x,y) \mathrm{d}y
$$</p>
<p>$$
\implies g(x)\int f_{XY}(x,y) \mathrm{d}y = \int yf_{XY}(x,y) \mathrm{d}y
$$</p>
<p>$$
\implies g(x) f_X(x) = \int yf_{XY}(x,y) \mathrm{d}y
$$</p>
<p>$$
\implies g(x)  = \int y\frac{f_{XY}(x,y)}{f_X(x)} \mathrm{d}y
$$</p>
<p>$$
\implies g(x)  = \int yf_{Y|X}(y|x) \mathrm{d}y=E(Y|X)
$$</p>
<h3 id="12-最优线性最小二乘估计beta-">1.2 最优线性最小二乘估计$\beta^* $</h3>
<p>$X  =(1,X_1,\ldots,X_k )^{\prime}$</p>
<p>$\beta  =(\beta _0,\beta _1,\ldots,\beta_k )^{\prime}$
$$
\min _{g \in \mathbf{A}} E[Y-g(X)]^{2}=\min _{\beta \in \mathbf{R}^{k+1}} E\left(Y-X^{\prime} \beta\right)^{2}
$$</p>
<p>The key feature of A is that g(X) = X 0β is linear in β; not in X</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223542.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223542.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223542.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223542.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223542.png"
        title="20200611223542.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223547.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223547.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223547.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223547.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223547.png"
        title="20200611223547.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223552.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223552.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223552.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223552.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223552.png"
        title="20200611223552.png" /></div></p>
<p>最优最小二乘估计量，当且仅当$E(xu)=0$(一阶条件)</p>
<p>why：soc Hessian matrix is positive definite provided E(XX ) is nonsingula</p>
<p>非奇异推出正定</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223608.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223608.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223608.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223608.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223608.png"
        title="20200611223608.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223623.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223623.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223623.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223623.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223623.png"
        title="20200611223623.png" /></div></p>
<h3 id="13-模型正确设定">1.3 模型正确设定</h3>
<p>模型具有经济解释意义的前提的模型正确设定$E(u|x) = 0$</p>
<p>模型正确设定：
$$
Y=X^{\prime} \beta+u, \beta \in \mathbb{R}^{k+1}
$$
如果存在某个参数值$\beta ^o \in  \mathbb{R}^{k+1}$，有
$$
E(Y|X) = X^{\prime} \beta^o
$$
则是对$E(Y|X)$的正确设定</p>
<p>若对任意$\beta  \in  \mathbb{R}^{k+1}$
$$
E(Y|X) \neq X^{\prime} \beta
$$
则模型设定错误。</p>
<p>如果模型正确设定，系数可以解释为期望边际效应
$$
\beta^{o}=\frac{\mathrm{d} E(Y | X)}{\mathrm{d} X}
$$
定理：如果模型正确设定$\beta^ * \overset{模型正确设定}{=} \beta ^o$</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223634.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223634.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223634.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223634.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223634.png"
        title="20200611223634.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223643.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223643.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223643.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223643.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223643.png"
        title="20200611223643.png" /></div></p>
<p>$$
E(\epsilon|X)=0 推出  E(\epsilon X) = 0
$$</p>
<h1 id="2-经典线性回归模型">2. 经典线性回归模型</h1>
<p>经典的含义是：经典回归假设</p>
<p>$Z_t= { Y_t,X^{\prime}<em>t }^n</em>{t=1}$是容量为n的样本，其中$Y_t$是一个标量，$X_t = (1,X_{1t}, \ldots,X_{kt})^{\prime}$
$$
\begin{aligned}
\boldsymbol{Y} &amp;=\left(Y_{1}, \cdots, Y_{n}\right)^{\prime}, n \times 1 \<br>
\boldsymbol{\varepsilon} &amp;=\left(\varepsilon_{1}, \cdots, \varepsilon_{n}\right)^{\prime}, n \times 1 \<br>
\boldsymbol{X} &amp;=\left(X_{1}, \cdots, X_{n}\right)^{\prime}, n \times K
\end{aligned}
$$</p>
<p>$$
\boldsymbol{X} = 
\begin{pmatrix} 
1 &amp; X_{11} &amp; \ldots &amp; X_{k1} \ 
1 &amp; X_{12} &amp; \ldots &amp; X_{k2} \<br>
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \<br>
1 &amp; X_{1n} &amp; \ldots &amp; X_{kn}
\end{pmatrix}
$$</p>
<p><strong>截面数据</strong>：样本之间相互独立（空间计量打破这一假设，假定样本之间存在地理关联）</p>
<p><strong>时间序列数据</strong>：本质区别是样本之间存在相关性</p>
<p><strong>面板数据</strong></p>
<h2 id="21-假定">2.1 假定</h2>
<h4 id="假设31-线性">假设3.1 线性</h4>
<p>$$
Y_t=X^{\prime}_t \beta^o + \varepsilon _t, \quad t=1,\ldots,n
$$</p>
<p>或者等价为
$$
\boldsymbol{Y} = \boldsymbol{X}\beta ^o+ \varepsilon
$$
该假设并不保证模型正确设定，模型正确设定当且仅当$E(\varepsilon_t|X_t)=0$</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223657.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223657.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223657.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223657.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223657.png"
        title="20200611223657.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223706.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223706.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223706.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223706.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223706.png"
        title="20200611223706.png" /></div></p>
<h4 id="假设32-严格外生性">假设3.2 严格外生性</h4>
<p>$$
E\left(\varepsilon_{t} | \boldsymbol{X}\right)=E\left(\varepsilon_{t} | X_{1}, \cdots, X_{t}, \cdots, X_{n}\right)=0 \quad t=1, \cdots, n
$$</p>
<p>由重复期望法则$E(\varepsilon _t| X_t)=0$，$E(\varepsilon_t) = 0 $（小信息集=0，如果大信息集条件期望为0）</p>
<p>如果严格外生性成立，则
$$
E(\boldsymbol{Y}|\boldsymbol{X})=E(\boldsymbol{X}\beta^o|\boldsymbol{X})+ E(\boldsymbol{\varepsilon} | \boldsymbol{X})=\boldsymbol{X}\beta^o
$$
意味着模型被正确设定。</p>
<p>进一步，对任意$t,s \in {1,\dots,n}$
$$
\begin{aligned}
E\left(X_{s} \varepsilon_{t}\right) &amp;=E\left[E\left(X_{s} \varepsilon_{t} | \boldsymbol{X}\right)\right] \<br>
&amp;=E\left[X_{s} E\left(\varepsilon_{t} | \boldsymbol{X}\right)\right] \<br>
&amp;=E\left(X_{s} \cdot 0\right) \<br>
&amp;=\mathbf{0}
\end{aligned}
$$
结合$E(\varepsilon_t)=0$，有$cov(X_s,\varepsilon_t)=0$。这排除了AR模型。</p>
<p>该假设的提出只是为了获得有限样本分布理论，对于大样本理论不需要严格外生性假设。</p>
<h4 id="假设33-非奇异">假设3.3 非奇异</h4>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223716.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223716.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223716.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223716.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223716.png"
        title="20200611223716.png" /></div></p>
<p>非奇异也可表述为最小特征值&gt;0，<strong>保证了无多重共线性</strong></p>
<p>假设(2)保无近似多重共线性</p>
<p>$X^{\prime}X$是对称阵，可以称为样本$X$的信息矩阵，因为它测度了$X$中的信息含量</p>
<h4 id="假设34-球形误差方差">假设3.4 球形误差方差</h4>
<p>条件同方差
$$
E(\varepsilon^2_t |\boldsymbol{X})=\sigma^2,t=1,\dots,n
$$
条件无自相关
$$
E(\varepsilon_t \varepsilon_s |\boldsymbol{X})=0,\quad t \neq s,t,s \in {1,\dots,n}
$$
假设3.2与3.4可以结合起来表述为
$$
E(\boldsymbol{\varepsilon} | \boldsymbol{X})=\mathbf{0}, \boldsymbol{E}\left(\boldsymbol{\varepsilon \varepsilon}^{\prime} | \boldsymbol{X}\right)=\sigma^{2} \boldsymbol{I}
$$
其中$\boldsymbol{I} \equiv \boldsymbol{I}_{n}$  是一个$\boldsymbol{n} \times \boldsymbol{n}$单位阵</p>
<h4 id="假设35-条件正态分布">假设3.5 条件正态分布</h4>
<p>$$
\boldsymbol{\varepsilon} | \boldsymbol{X} \sim N\left(\mathbf{0}, \sigma^{2} \boldsymbol{I}\right)
$$
等价于$\varepsilon_t \sim IID \quad N(0, \sigma^2)$</p>
<p>假设3.5可以推导出假设3.2和3.4（$E(\boldsymbol{\varepsilon} | \boldsymbol{X})=\mathbf{0}, \boldsymbol{E}\left(\boldsymbol{\varepsilon \varepsilon}^{\prime} | \boldsymbol{X}\right)=\sigma^{2} \boldsymbol{I}$），进一步
$$
f(\boldsymbol{\varepsilon} |  \boldsymbol{X})=\frac{1}{(\sqrt{2 \pi \sigma^{2}})^{n}} \exp \left(-\frac{\boldsymbol{\varepsilon}^{\prime} \boldsymbol{\varepsilon}}{2 \sigma^{2}}\right)=f(\boldsymbol{\varepsilon})
$$</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223847.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223847.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223847.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223847.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611223847.png"
        title="20200611223847.png" /></div></p>
<p>可以推导出，$\boldsymbol{\varepsilon}$ 独立于 $\boldsymbol{X}$</p>
<p>并且正态性+$Cov(\varepsilon_t, \varepsilon_s)=0, \forall t \neq s$可推导出$\varepsilon_t$独立于$\varepsilon_s$</p>
<p>因此假设3.5还能推出$\varepsilon_t, t=1,2,\ldots$是IID的正态分布</p>
<p>综上，这是一个非常严格的假定。</p>
<h2 id="22-普通最小二乘估计ols">2.2 普通最小二乘估计OLS</h2>
<h3 id="221-ols估计量的存在性">2.2.1 OLS估计量的存在性</h3>
<p>【OLS 估计量，ordinary least squares】定义线性回归模型$Y_t = X'<em>t \beta + u_t$  的残差平方和(sum of squared residuals, SSR)为
$$
\begin{equation}\begin{aligned}
\operatorname{SSR}(\beta) &amp; \equiv(\boldsymbol{Y}-\boldsymbol{X} \beta)^{\prime}(\boldsymbol{Y}-\boldsymbol{X} \beta) \<br>
&amp;=\sum</em>{t=1}^{n}\left(Y_{t}-X_{t}^{\prime} \beta\right)^{2}
\end{aligned}\end{equation}
$$</p>
<p>则OLS估计量是以下最优化问题的解
$$
\begin{equation}\hat{\boldsymbol{\beta}}=\arg \min _{\boldsymbol{\beta} \in \Bbb{R}^{K}} SSR(\boldsymbol{\beta})\end{equation}
$$</p>
<p>【定理 2.1】在假设3.1和3.3(1)下，OLS估计量$\hat{\beta} $存在，并且
$$
\begin{equation}\begin{aligned}
\hat{\beta} &amp;=\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{X}^{\prime} \boldsymbol{Y} \<br>
&amp;=\left(\frac{1}{n} \sum_{t=1}^{n} X_{t} X_{t}^{\prime}\right)^{-1} \frac{1}{n} \sum_{t=1}^{n} X_{t} Y_{t}
\end{aligned}\end{equation}
$$
证明：
$$
\begin{equation}\begin{aligned}
\frac{\operatorname{d} SSR(\beta)}{\mathrm{d} \beta} &amp;=\frac{\mathrm{d}}{\mathrm{d} \beta} \sum_{t=1}^{n}\left(Y_{t}-X_{t}^{\prime} \beta\right)^{2} \<br>
&amp;=\sum_{t=1}^{n} \frac{\partial\left(Y_{t}-X_{t}^{\prime} \beta\right)^{2}}{\partial \beta} \<br>
&amp;=\sum_{t=1}^{n} 2\left(Y_{t}-X_{t}^{\prime} \beta\right) \frac{\partial\left(Y_{t}-X_{t}^{\prime} \beta\right)}{\partial \beta} \<br>
&amp;=-2 \sum_{t=1}^{n} X_{t}\left(Y_{t}-X_{t}^{\prime} \beta\right) \<br>
&amp;=-2 \boldsymbol{X}^{\prime}(\boldsymbol{Y}-\boldsymbol{X} \beta)=\bf{0}
\end{aligned}\end{equation}
$$
结合假设3.1(1)非奇异（$\lambda_{min}(X^{\prime} X)&gt;0$）有
$$
\begin{equation}\hat{\beta}=\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{X}^{\prime} \boldsymbol{Y}\end{equation}
$$
检查二阶条件，$K \times K$ Hessian矩阵
$$
\begin{aligned}
\frac{\partial^{2} S S R(\beta)}{\partial \beta \partial \beta^{\prime}} &amp;=-2 \sum_{t=1}^{n} \frac{\partial}{\partial \beta^{\prime}}\left[\left(Y_{t}-X_{t}^{\prime} \beta\right) X_{t}\right] \<br>
&amp;=2 \bf{X}^{\prime} \bf{X}
\end{aligned}
$$
根据假设3.1(1)，Hessian矩阵正定，从而$\hat{\beta}$是全局最优解。</p>
<h3 id="222-hatbeta与-beta-">2.2.2 $\hat{\beta}$与$ \beta^* $</h3>
<p>不加证明地给出
$$
\begin{aligned}
SSR(\beta)&amp;\stackrel{p}{\rightarrow}\operatorname{MSE}(\beta)=E[Y_t-X'_t\beta]^{2} \<br>
\hat{\beta}&amp;\stackrel{p}{\rightarrow}\beta^<em>=
\left[E(\boldsymbol{XX'})\right]^{-1}E(\boldsymbol{XY'})
\end{aligned}
$$
联系第二章，$SSR(\beta)$与$\hat{\beta}$分别是$MSE(\beta)$与$ \beta^</em> $的样本类似物(sample analogs)</p>
<blockquote>
<p>Whenever you have something unknown, always replace it with sample analogs.</p>
</blockquote>
<h3 id="223-残差及其性质">2.2.3 残差及其性质</h3>
<p>$Y_i = X'<em>t\hat{\beta}$称为观测值$Y_t $的拟合值(fitted value)或预测值(predicted value)。另外，$e_t=Y_t - \hat{Y}<em>t$是观测值$Y_t $的估计残差(estimated residual)或预测误差(prediction error)。其中
$$
\begin{aligned}
\mathbf{e}</em>{t} &amp;=Y</em>{t}-\hat{Y}<em>{t} \<br>
&amp;=\left(X</em>{t}^{\prime} \beta^{o}+\varepsilon_{t}\right)-X_{t}^{\prime} \hat{\beta} \<br>
&amp;=\varepsilon_{t}-X_{t}^{\prime}\left(\hat{\beta}-\beta^{o}\right)
\end{aligned}
$$
其中真实扰动项$ \varepsilon_t $是不可避免的，而第二项$X'_t(\hat{\beta}-\beta^o)$是估计误差：当样本容量越大(从而$\hat{\beta}$越靠近$\beta^o$)，这一项将变得越小，乃至忽略不计。</p>
<blockquote>
<p>prediction可以是对过去的预测，forecast是对将来的预测</p>
</blockquote>
<p>注意到最小化问题$\min <em>{\boldsymbol{\beta} \in \Bbb{R}^{K}} SSR(\boldsymbol{\beta})$的一阶条件中，
$$
\boldsymbol{X}^{\prime} \boldsymbol{e}=\sum</em>{t=1}^{n} X_{t} e_{t}=\mathbf{0}
$$
这意味着残差向量$\boldsymbol{e}$与解释变量矩阵$\bf{X}$正交(无论模型是否正确设定)。进一步，若$\bf{X}_t$包含截距项，则$\boldsymbol{X}^{\prime} \boldsymbol{e}$意味着$\sum^n_{t=1}e^t=0$。</p>
<h2 id="23-拟合优度与模型选择准则">2.3 拟合优度与模型选择准则</h2>
<h3 id="231-拟合优度-mathcalr2-">2.3.1 拟合优度$ \mathcal{R}^2 $</h3>
<p>残差波动越小，拟合优度越高</p>
<p>通过$\boldsymbol{Y}=\hat{\boldsymbol{Y}}+\boldsymbol{e}$，
$$
\begin{aligned}
\boldsymbol{Y}^{\prime} \boldsymbol{Y}&amp;=(\hat{\boldsymbol{Y}}+\boldsymbol{e})'(\hat{\boldsymbol{Y}}+\boldsymbol{e}) \<br>
&amp;=\hat{\boldsymbol{Y}}^{\prime} \hat{\boldsymbol{Y}}+\boldsymbol{e}^{\prime} \boldsymbol{e}+2 \hat{\boldsymbol{Y}}^{\prime} \boldsymbol{e} \<br>
&amp;= \hat{\boldsymbol{Y}}\boldsymbol{\hat{Y}}+\boldsymbol{e}^{\prime} \boldsymbol{e}
\end{aligned}
$$
其中
$$
\hat{\boldsymbol{Y}}^{\prime} \boldsymbol{e}=(\boldsymbol{X}\hat{\beta})^{\prime}\boldsymbol{e}=\hat{\beta}^{\prime}\boldsymbol{X}^{\prime}\boldsymbol{e}=\hat{\beta}^\prime\boldsymbol{0}=0
$$
因此
$$
\frac{\hat{\boldsymbol{Y}}^{\prime} \hat{\boldsymbol{Y}}}{\hat{\boldsymbol{Y}}^{\prime} \hat{\boldsymbol{Y}}}=\frac{\hat{\boldsymbol{Y}}^{\prime} \hat{\boldsymbol{Y}}}{\hat{\boldsymbol{Y}}^{\prime} \hat{\boldsymbol{Y}}}-\frac{\boldsymbol{e}^{\prime} \boldsymbol{e}}{\hat{\boldsymbol{Y}}^{\prime} \hat{\boldsymbol{Y}}}=1-\frac{\boldsymbol{e}^{\prime} \boldsymbol{e}}{\hat{\boldsymbol{Y}}^{\prime} \hat{\boldsymbol{Y}}}
$$
【非中心化$\mathcal{R}^{2}$】 非中心化多元相关系数平方$ R^2 $(uncentered squared multi-correlation coefficient)定义为
$$
\mathcal{R}<em>{\mathrm{uc}}^{2}=\frac{\hat{\boldsymbol{Y}}^{\prime} \hat{\boldsymbol{Y}}}{\boldsymbol{Y}^{\prime} \boldsymbol{Y}}=1-\frac{\boldsymbol{e}^{\prime} \boldsymbol{e}}{\boldsymbol{Y}^{\prime} \boldsymbol{Y}}
$$
$\mathcal{R}</em>{\mathrm{uc}}^{2}$的含义是因变量$ {Y_t}$ 的样本二次型变动可以被预测值${\hat{Y}<em>t}$的样本二次型变动所预测的比例。根据定义，总有$0 \le \mathcal{R}</em>{\mathrm{uc}}^{2} \le1$。</p>
<p>下面定义一个相近的指标， 称为中心化多元相关系数平方 (centered squared multi-correlation coefficiet)，通常简称为$ \mathcal{R}^2 $。</p>
<p>【中心化$ \mathcal{R}^2 $或决定系数(Coefficient of Determination)】决定系数定义为
$$
\mathcal{R}^2  \equiv 1-\frac{\sum_{t-1}^{n} e_{t}^{2}}{\sum_{t=1}^{n}\left(Y_{t}-\bar{Y}\right)^{2}}
$$
其中 $\bar{Y}=n^{-1} \sum_{t=1}^{n} Y_{t}$是样本均值。</p>
<p>当$X_{t}$包含截距项即$X_{0t}=1$时，可进行如下正交分解	
$$
\begin{aligned}
\sum_{t=1}^{n}\left(Y_{t}-\bar{Y}\right)^{2} &amp;=\sum_{t=1}^{n}\left(\hat{Y}_{t}-\bar{Y}+Y_{t}-\hat{Y}_{t}\right)^{2} \<br>
&amp;=\sum_{t=1}^{n}\left(\hat{Y}_{t}-Y\right)^{2}+\sum_{t=1}^{n} e_{t}^{2}+2 \sum_{t=1}^{n}\left(\hat{Y}_{t}-Y\right) e_{t} \<br>
&amp;=\sum_{t=1}^{n}\left(\hat{Y}_{t}-\bar{Y}\right)^{2}+\sum_{t=1}^{n} e_{t}^{2}
\end{aligned}
$$
其中交差项
$$
\begin{aligned}
\sum_{t=1}^{n}\left(\hat{Y}_{t}-\bar{Y}\right) e_{t} &amp;=\sum_{t=1}^{n} \hat{Y}_{t} e_{t}-\bar{Y} \sum_{t=1}^{n} e_{t} \<br>
&amp;=\hat{\beta}^{\prime} \sum_{t=1}^{n} X_{t} e_{t}-\bar{Y} \sum_{t=1}^{n} e_{t} \<br>
&amp;=\hat{\beta}^{\prime}\left(\mathrm{X}^{\prime} e\right)-\bar{Y} \sum_{t=1}^{n} e_{t} \<br>
&amp;=\hat{\beta}^{\prime} \cdot \boldsymbol{0}-\bar{Y} \cdot 0 \<br>
&amp;=0
\end{aligned}
$$
这里使用了OLS估计的一阶条件，即$\boldsymbol{X}^{\prime} \boldsymbol{e}=0$ 和 $\sum_{t=1}^{n} e_{t}=0$。从而
$$
\begin{aligned}
\mathcal{R}^{2} &amp; \equiv 1-\frac{e^{\prime} e}{\sum_{t=1}^{n}\left(Y_{t}-\bar{Y}\right)^{2}} \<br>
&amp;=\frac{\sum_{t=1}^{n}\left(Y_{t}-\bar{Y}\right)^{2}-\sum_{t=1}^{n} e_{t}^{2}}{\sum_{t=1}^{n}\left(Y_{t}-\bar{Y}\right)^{2}} \<br>
&amp;=\frac{\sum_{t=1}^{n}\left(\hat{Y}_{t}-\bar{Y}\right)^{2}}{\sum_{t=1}^{n}\left(Y_{t}-\bar{Y}\right)^{2}}
\end{aligned}
$$
并且有
$$
0 \le \mathcal{R}^2 \le 1
$$
反之，若$ X_t $不包含截距项，则
$$
\begin{aligned}
\sum_{t=1}^{n}\left(Y_{t}-\bar{Y}\right)^{2} &amp;=\sum_{t=1}^{n}\left(\hat{Y}_{t}-\bar{Y}\right)^{2}+\sum_{t=1}^{n} e_{t}^{2}+2 \sum_{t=1}^{n}\left(\hat{Y}_{t}-\bar{Y}\right) e_{t} \<br>
&amp; \neq \sum_{t=1}^{n}\left(\hat{Y}_{t}-\bar{Y}\right)^{2}+\sum_{t=1}^{n} e_{t}^{2}
\end{aligned}
$$
在这种情况下，$\mathcal{R}^2 $可能为负值。因为交叉项$2 \sum_{t=1}^{n}\left(\hat{Y}_{t}-\bar{Y}\right) e_{t}$可能为负值。</p>
<p>【定理 2.2】当$ X_t $包含截距项时，$\mathcal{R}^2$是${\hat{Y}_t}$与${Y_i}$的样本方差的比值。</p>
<p>证明：</p>
<p>${\hat{Y}<em>t}$的样本均值为
$$
\begin{aligned}
\bar{\hat{Y}}&amp;=\frac{1}{n} \sum</em>{t=1}^{n} \hat{Y}<em>{t}\<br>
&amp;=\frac{1}{n} \sum</em>{i=1}^{n}\left(Y_{t}-e_{t}\right)\<br>
&amp;=\bar{Y}-\frac{1}{n} \sum_{i=1}^{n} e_{t}\<br>
&amp;=\bar{Y}
\end{aligned}
$$
其中$\sum_{t=1}^{n} e_{t}=0$要求$ X_t $包含截距项。从而
$$
\begin{aligned}
\mathcal{R}^{2} &amp;=\frac{\sum_{t=1}^{n}\left(\hat{Y}_{t}-\bar{Y}\right)^{2}}{\sum_{t=1}^{n}\left(Y_{t}-\bar{Y}\right)^{2}}\<br>
&amp;=\frac{\frac{1}{n-1}\sum_{t=1}^{n}\left(\hat{Y}_{t}-\bar{\hat{Y}}\right)^{2}}{\frac{1}{n-1}\sum_{t=1}^{n}\left(Y_{t}-\bar{Y}\right)^{2}}\<br>
&amp;=\frac{S^2_{\hat{Y}}}{S^2_Y}
\end{aligned}
$$
此时，中心化$\mathcal{R}^2 $和非中心化$ \mathcal{R}_{\mathrm{uc}}^{2} $有相似的解释，即$\mathcal{R}^2 $测度$ {Y_i} $的样本方差中被预测值${\hat{Y}_t}$的样本方差所预测的比例。</p>
<p>【定理 2.3】当$ X_t $包含截距项时，中心化$\mathcal{R}^2$是${Y_t}$和${\hat{Y_t}}$之间相关系数的平方
$$
\mathcal{R}^2=\hat{\rho}^2_{Y\hat{Y}}
$$
证明：</p>
<p>应用前文所证交叉项$\sum_{t=1}^{n}\left(\hat{Y}_{t}-\bar{Y}\right) e_{t}=0$，有
$$
\begin{aligned}
cov(Y_t, \hat{Y_t})
&amp;=\frac{1}{n-1}\sum^n_{t=1}(\hat{Y}_{t}-\bar{Y})({Y}_{t}-\bar{Y})\<br>
&amp;=\frac{1}{n-1}\sum^n_{t=1}(\hat{Y}_{t}-\bar{Y})({Y}_{t}-\hat{Y_t}+\hat{Y_t}-\bar{Y})\<br>
&amp;=\frac{1}{n-1}\left[\sum^n_{t=1}(\hat{Y}_{t}-\bar{Y})({Y}_{t}-\hat{Y_t})+\sum^n_{t=1}(\hat{Y}_{t}-\bar{Y})^2\right]\<br>
&amp;=\frac{1}{n-1}\sum^n_{t=1}(\hat{Y}_{t}-\bar{Y})^2=S^2_{\hat{Y}}
\end{aligned}
$$
结合定理2.2
$$
\begin{aligned}
\hat{\rho}^2_{Y\hat{Y}}
&amp;=\frac{cov^2(Y_t, \hat{Y_t})}{S^2_{\hat{Y}}S^2_{Y}}\<br>
&amp;=\frac{[S^2_{\hat{Y}}]^2}{S^2_{\hat{Y}}S^2_{Y}}\<br>
&amp;=\frac{S^2_{\hat{Y}}}{S^2_Y}\<br>
&amp;=\mathcal{R}^2
\end{aligned}
$$
向量的形式</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224220.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224220.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224220.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224220.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224220.png"
        title="20200611224220.png" /></div></p>
<p>利用$M^0$矩阵证明</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224243.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224243.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224243.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224243.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224243.png"
        title="20200611224243.png" /></div></p>
<p>i，I都是单位向量</p>
<p>由于拟合值 $\hat{Y}<em>{t}=X</em>{t}^{\prime} \hat{\beta}=\hat{\beta}<em>{0}+\sum</em>{j=1}^{k} \hat{\beta}<em>{j} X</em>{j t}$是$\left{X_{j t}\right}_{j=1}^{k}$的线性组合，$ \mathcal{R} $可视为$Y_{t}$ 与 $\left{X_{j t}\right}_{j=1}^{k},$之间的多元样本相关系数。因此$R^{2}$被称为多元相关系数平方(squared multi-correlation coefficient)。</p>
<p>这说明$ \mathcal{R}^2 $测度了因变量$Y_t$与解释变量$X_t$之间的线性关联程度，是一种相关关系，而非因果关系。当$E(Y_t|X_t)$是$X_t$的非线性函数时，用$ \mathcal{R}^2 $来测度非线性回归模型的拟合优度是不合适的。</p>
<p>事实上对任何给定的随机样本$\left{Y_{t}, X_{t}^{\prime}\right}^n_{t=1}$，$\mathcal{R}^{2}$是解释变量数目的非减函数。</p>
<p>【定理 2.4】假设 $\left{Y_{t}, X_{1 t}, \ldots, X_{(k+q) t}\right}^{n}_{t=1}$是容量为$n$的随机样本，$\mathcal{R}^2_1$是下列线性回归模型的中心化拟合优度
$$
Y_{t}=X_{t}^{\prime} \beta+u_{t}
$$
其中$X_{t}=\left(1, X_{1 t}, \ldots, X_{k t}\right)^{\prime}$，$\beta$是$K \times 1$ 未知参数向量，$R_{2}^{2}$ 是下面扩展的线性回归模型的中心化拟合优度
$$
Y_{t}=\tilde{X}_{t}^{\prime} \gamma+v_{t}
$$
其中$\tilde{X}_{t}=\left(1, X_{1 t}, \ldots, X_{k t}, X_{(k+1) t}, \ldots, X_{(k+q) t}\right)^{\prime}$， $\gamma$ 是$(K+q) \times 1$未知参数向量。则
$$
R_{2}^{2} \geq R_{1}^{2}
$$
证明：根据定义有
$$
\begin{aligned}
R_{1}^{2} &amp;=1-\frac{e^{\prime} e}{\sum_{t=1}^{n}\left(Y_{t}-\bar{Y}\right)^{2}} \<br>
R_{2}^{2} &amp;=1-\frac{\hat{e}^{\prime} \tilde{e}}{\sum_{t=1}^{n}\left(Y_{t}-Y\right)^{2}}
\end{aligned}
$$
其中$\boldsymbol{e} $是$\boldsymbol{Y}$对$\boldsymbol{X} $回归的残差向量, $\boldsymbol{\tilde{e}} $是$\boldsymbol{Y}$对$\boldsymbol{\tilde{X}} $回归的残差向量。</p>
<p>只需要证明$\tilde{e}^{\prime} \tilde{e} \leq e^{\prime} e .$即可。OLS估计量$\hat{\gamma}=\left(\tilde{\boldsymbol{X}}^{\prime} \tilde{\boldsymbol{X}}\right)^{-1} \tilde{\boldsymbol{X}}^{\prime} \boldsymbol{Y}$ 是使扩展模型$Y_{t}=\tilde{X}_{t}^{\prime} \gamma+v_{t}$的$S S R(\gamma)$最小化的最优解，有
$$
\tilde{e}^{\prime} \tilde{e}=\sum_{t=1}^{n}\left(Y_{t}-\tilde{X}_{t}^{\prime} \hat{\gamma}\right)^{2} \leq \sum_{t=1}^{n}\left(Y_{t}-\tilde{X}_{t}^{\prime} \gamma\right)^{2} \text { for all } \gamma \in \mathbb{R}^{K+q}
$$
令
$$
\gamma=\left(\hat{\beta}^{\prime}, \boldsymbol{0}^{\prime}\right)^{\prime}
$$
其中$\hat{\beta}=\left(\mathrm{X}^{\prime} \mathrm{X}\right)^{-1} \mathrm{X}^{\prime} Y$是$Y_{t}=X_{t}^{\prime} \beta+u_{t}$的OLS估计量。则有
$$
\begin{aligned}
\tilde{e}^{\prime} \tilde{e} &amp; \leq \sum_{t=1}^{n}\left(Y_{t}-\sum_{j=0}^{k} \hat{\beta}_{j} X_{j t}-\sum_{j=k+1}^{k+q} 0 \cdot X_{j t}\right)^{2} \<br>
&amp;=\sum_{t=1}^{n}\left(Y_{t}-X_{t}^{\prime} \hat{\beta}\right)^{2} \<br>
&amp;=e^{\prime} e
\end{aligned}
$$
因此$R_{1}^{2} \leq R_{2}^{2} $。</p>
<p>定理2.4表明：首先，$ \mathcal{R}^2 $可用于解释变量数目相等的线性回归模型的比较，但它不适用于比较不同解释变量数目的线性回归模型，因为模型的解释变量越多$ \mathcal{R}^2 $会越大，即使新增加的解释变量对因变量没有真正的解释力，$ \mathcal{R}^2 $也会增加。其次$ \mathcal{R}^2 $也不是正确模型设定的判断标准。$ \mathcal{R}^2 $高并不意味着模型设定正确，同 样，正确的模型设定也并不意味着高的$ \mathcal{R}^2 $。事实上，给定解释变量$X_t$，$ \mathcal{R}^2 $值的大小与线性回归模型的信噪比(signal to noise ratio) 有关。</p>
<p>调整$R^2$,</p>
<p>分子是残差的样本方差！</p>
<p>$R^2$在时序数据中往往较高（滞后项对当前项解释力较强），故意义不大；截面数据中有一定参考价值，大于0.3是较好的模型。</p>
<h3 id="232-aicbic">2.3.2 AIC&amp;BIC</h3>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224256.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224256.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224256.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224256.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224256.png"
        title="20200611224256.png" /></div></p>
<h2 id="24-ols估计量的统计性质">2.4 OLS估计量的统计性质</h2>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224305.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224305.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224305.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224305.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224305.png"
        title="20200611224305.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224317.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224317.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224317.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224317.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224317.png"
        title="20200611224317.png" /></div></p>
<p>幂等矩阵的特征值只能是1或者0</p>
<p>M是残差的操作符e=MY = M$\epsilon$</p>
<p>(2)是$ \epsilon $的线性组合</p>
<p>(4)正太分布随鸡变量$ \epsilon $的二次型服从卡方分布(SSR)</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224327.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224327.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224327.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224327.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224327.png"
        title="20200611224327.png" /></div></p>
<p>(2)当$\tau = (1,0,\ldots,0)'$，则$\tau&rsquo;var(\hat{\beta}|X)\tau=var(\hat{\beta_0})$</p>
<p>$MSE(\hat{\beta}_0|X)=var(\hat{\beta}_0|X)+Bias^2(\hat{\beta})\rightarrow 0$, as $n \rightarrow \infty$</p>
<p>(3)+联合正态分布退出独立，用于推导假设检验的有限分布</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224335.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224335.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224335.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224335.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224335.png"
        title="20200611224335.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224345.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224345.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224345.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224345.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224345.png"
        title="20200611224345.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224353.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224353.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224353.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224353.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224353.png"
        title="20200611224353.png" /></div></p>
<p>定理3.5 (4)(5)对于构建假设检验(t检验)有重要意义</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224358.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224358.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224358.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224358.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224358.png"
        title="20200611224358.png" /></div></p>
<p>定理3.5(4)证明的一步</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224409.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224409.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224409.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224409.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224409.png"
        title="20200611224409.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224426.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224426.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224426.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224426.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224426.png"
        title="20200611224426.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224426.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224426.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224426.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224426.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224426.png"
        title="20200611224426.png" /></div></p>
<p>直观理解是方差最小</p>
<p>高斯定理：严格外生性，球形方差，OLS是最优线性无偏估计量(BLUE)</p>
<h2 id="25-ols估计量的抽样分布">2.5 OLS估计量的抽样分布</h2>
<p>引入假定3.5</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224459.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224459.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224459.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224459.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224459.png"
        title="20200611224459.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224512.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224512.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224512.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224512.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224512.png"
        title="20200611224512.png" /></div></p>
<h2 id="26-残差方差估计量的分布">2.6 残差方差估计量的分布</h2>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224448.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224448.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224448.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224448.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224448.png"
        title="20200611224448.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224744.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224744.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224744.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224744.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224744.png"
        title="20200611224744.png" /></div></p>
<h2 id="27-假设检验">2.7 假设检验</h2>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224752.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224752.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224752.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224752.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224752.png"
        title="20200611224752.png" /></div></p>
<p>J&gt;K可能会产生奇异矩阵</p>
<p>基本思想</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224758.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224758.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224758.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224758.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224758.png"
        title="20200611224758.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224809.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224809.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224809.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224809.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224809.png"
        title="20200611224809.png" /></div></p>
<h3 id="271-j1">2.7.1 J=1</h3>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224816.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224816.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224816.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224816.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224816.png"
        title="20200611224816.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224828.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224828.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224828.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224828.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224828.png"
        title="20200611224828.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224836.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224836.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224836.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224836.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224836.png"
        title="20200611224836.png" /></div></p>
<p>检验标准</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224845.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224845.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224845.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224845.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224845.png"
        title="20200611224845.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224852.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224852.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224852.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224852.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224852.png"
        title="20200611224852.png" /></div></p>
<h3 id="272-j1">2.7.2 J&gt;1</h3>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224901.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224901.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224901.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224901.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224901.png"
        title="20200611224901.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224909.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224909.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224909.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224909.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224909.png"
        title="20200611224909.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224915.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224915.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224915.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224915.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224915.png"
        title="20200611224915.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224926.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224926.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224926.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224926.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224926.png"
        title="20200611224926.png" /></div></p>
<p>更加常用的方法：本质上是LM检验</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224932.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224932.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224932.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224932.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224932.png"
        title="20200611224932.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224938.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224938.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224938.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224938.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224938.png"
        title="20200611224938.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224945.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224945.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224945.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224945.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224945.png"
        title="20200611224945.png" /></div></p>
<p>Wald Test</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224951.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224951.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224951.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224951.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611224951.png"
        title="20200611224951.png" /></div></p>
<h2 id="28-重要应用">2.8 重要应用</h2>
<h3 id="281-检验所有解释变量的联合显著性">2.8.1 检验所有解释变量的联合显著性</h3>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225000.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225000.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225000.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225000.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225000.png"
        title="20200611225000.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225009.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225009.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225009.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225009.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225009.png"
        title="20200611225009.png" /></div></p>
<p>e.g. 检验有效市场：任一系数不为零，则市场不是有效市场</p>
<h3 id="283-检验遗漏变量">2.8.3 检验遗漏变量</h3>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225019.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225019.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225019.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225019.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225019.png"
        title="20200611225019.png" /></div></p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225027.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225027.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225027.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225027.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225027.png"
        title="20200611225027.png" /></div></p>
<p>e.g. 格兰杰因果检验：预测力非因果性</p>
<p>Chow Test</p>
<p>

<div style="text-align: center"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225036.png"
        data-srcset="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225036.png, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225036.png 1.5x, https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225036.png 1.6x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/Henrry-Wu/FigBed/Figs/20200611225036.png"
        title="20200611225036.png" /></div></p>
<h2 id="29-广义最小二乘估计gls">2.9 广义最小二乘估计GLS</h2>
</div>

            <div class="post"><div class="post-info-share">
    <span><a class="share-icon share-twitter" href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://henrywu97.github.io/chapter12/" data-title="" data-via="xxxx"><i class="fab fa-twitter fa-fw"></i></a><a class="share-icon share-facebook" href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://henrywu97.github.io/chapter12/"><i class="fab fa-facebook-square fa-fw"></i></a><a class="share-icon share-line" href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://henrywu97.github.io/chapter12/" data-title=""><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/line.svg"></i></a><a class="share-icon share-weibo" href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://henrywu97.github.io/chapter12/" data-title=""><i class="fab fa-weibo fa-fw"></i></a></span>
</div>
<div class="footer-post-author"style="border-radius: 10px;border-bottom: solid 2px #ececec">
    <div class="author-avatar"><a href="" target="_blank"><img alt="" src="" border="0"></a></div>
    <div class="author-info">
        <div class="name"><a href="" target="_blank"></a></div>
        <div class="number-posts"></span></div>
    </div>
</div><div class="post-footer" id="post-footer"><div class="post-navigation"><div class="post-nav-box nav-box-prev">
            <a class="nav-box" href="/5.-modern-portfolio-theory/"><span class="nav-icon"><svg aria-hidden="true" data-prefix="fas" data-icon="chevron-circle-left" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M256 504C119 504 8 393 8 256S119 8 256 8s248 111 248 248-111 248-248 248zM142.1 273l135.5 135.5c9.4 9.4 24.6 9.4 33.9 0l17-17c9.4-9.4 9.4-24.6 0-33.9L226.9 256l101.6-101.6c9.4-9.4 9.4-24.6 0-33.9l-17-17c-9.4-9.4-24.6-9.4-33.9 0L142.1 239c-9.4 9.4-9.4 24.6 0 34z"></path></svg></span><div style="text-align: right;padding-left: 10px"><div class="nav-text-h">Next article</div><span class="nav-text"></span></div></a>
        </div>
        <div class="post-nav-box nav-box-next">
            <a class="nav-box" href="/6.-instrumental-variables-regression/"><div style="padding-right: 10px"><div class="nav-text-h">Next article</div><span class="nav-text"></span></div><span class="nav-icon"><svg aria-hidden="true" data-prefix="fas" data-icon="chevron-circle-right" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M256 8c137 0 248 111 248 248S393 504 256 504 8 393 8 256 119 8 256 8zm113.9 231L234.4 103.5c-9.4-9.4-24.6-9.4-33.9 0l-17 17c-9.4 9.4-9.4 24.6 0 33.9L285.1 256 183.5 357.6c-9.4 9.4-9.4 24.6 0 33.9l17 17c9.4 9.4 24.6 9.4 33.9 0L369.9 273c9.4-9.4 9.4-24.6 0-34z"></path></svg></span></a>
        </div></div></div>
</div>
        </div>
    <div id="toc-final"></div>
    </article><div class="page single comments content-block-position"><div id="comments"><div id="remark42" class="comment" style="padding-top: 1.5rem"></div>
            <script>
                var themeRemark = document.body.getAttribute('theme')
                var remark_config = {
                    host: 'https:\/\/comments.upagge.ru',
                    site_id: 'documentation',
                    components: ['embed'],
                    theme: themeRemark,
                    locale: 'en',
                    show_email_subscription: '',
                    page_title: ''
                };

                (function(c) {
                    for(var i = 0; i < c.length; i++){
                        var d = document, s = d.createElement('script');
                        s.src = remark_config.host + '/web/' +c[i] +'.js';
                        s.defer = true;
                        (d.head || d.body).appendChild(s);
                    }
                })(remark_config.components || ['embed']);
            </script></div></div></div></main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.80.0">Hugo</a> | Theme - <a href="https://ublogger.netlify.app/?utm_source=https://henrywu97.github.io/&utm_medium=footer&utm_campaign=config&utm_term=1.2.0" target="_blank" title="uBlogger 1.2.0"><i class="fas fa-pencil-alt fa-fw"></i> uBlogger</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span>2021</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank"></a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><script src="https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js"></script><script src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js"></script><script src="https://cdn.jsdelivr.net/npm/algoliasearch@4.2.0/dist/algoliasearch-lite.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js"></script><script>window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"search":{"algoliaAppID":"PASDMWALPK","algoliaIndex":"index.en","algoliaSearchKey":"b42948e51daaa93df92381c8e2ac0f93","highlightTag":"em","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"algolia"}};</script><script src="/js/theme.min.js"></script><script src="/js/jquery-3.5.1.min.js"></script>
    <script>
        (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
            m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
        (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

        ym("70532758", "init", {
            clickmap:true,
            trackLinks:true,
            accurateTrackBounce:true
        });
    </script>
    <noscript><div><img src="https://mc.yandex.ru/watch/69594475" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
    </body>
</html>
